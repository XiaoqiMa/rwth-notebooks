{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home assignment 2\n",
    "\n",
    "You should work on the assignement in groups of 2 participants. \n",
    "\n",
    "Upload your solution as a jupyter notebook to L2P by 26th of June 23:59h. (The deadline is strict)\n",
    "\n",
    "Do not forget to specify the names of all contributing students in the jupyter notebook.\n",
    "\n",
    "You should add comments to your code where necessary and print the relevant results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dynamic PageRank\n",
    "Consider a random walk setting where the transistion matrix changes over time. At any point of time the probability of a random surfer to jump to a linked page is proportional to the number of previous visits. To start with all the pages are equally likely to be chosen but as the walk continues and the nodes are visited the transition probability changes as proportional to number of previous visits. For example let a page 'a' is linked to pages 'b', 'c' and 'd'. The random surfer currently resides at 'a' and the pages 'b', 'c' and 'd' have already been visited 5, 3 and 2 times respectively. The transition probability would be 0.5, 0.3 and 0.2 respectively. As a new node is viited the probabilities change. The random surfer continues to surf with probability 0.8. Generate 100 random walks and rank the nodes based on the frequency of visit. The random walk should be performed on a drected Erdos-Renyi graph with number of nodes n=200 and probability of edge creation p = 0.4. \n",
    "\n",
    "Hint: Use networkx library for generating graph.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "walks = 100\n",
    "c_p = 0.8\n",
    "\n",
    "freq_visit = [1 for i in range(200)]\n",
    "G = nx.erdos_renyi_graph(200, 0.4, directed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[143, 4, 99, 110, 193, 68, 100, 115, 119, 133]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while walks>0:\n",
    "    start = np.random.randint(200) # randomly select a start node\n",
    "    l = 0\n",
    "    while True:\n",
    "        freq_visit[start]+=1\n",
    "        nbrs = [nbr for nbr in G.neighbors(start)]\n",
    "        trans_prob = [freq_visit[node] for node in nbrs]\n",
    "        sum_ = sum(trans_prob)\n",
    "        trans_prob = [val/sum_ for val in trans_prob]\n",
    "        nxt = np.random.choice(nbrs,p=trans_prob)\n",
    "        start = nxt\n",
    "        if np.random.uniform(0,1)>0.8:\n",
    "            break\n",
    "\n",
    "    walks-=1\n",
    "\n",
    "\n",
    "sorted(range(len(freq_visit)), key=lambda k: freq_visit[k], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Recommendation\n",
    "a. Compare the recommendation algorithms (SVD, NMF, Baseline, k-NN and Random) available in surprise package on movielens dataset in terms of RMSE and MAE.\n",
    "\n",
    "b. Consider the movielens dataset and divide it into (i) training set with 50% of the data (train the algorithms on this part) and (ii) 25% validation set and (iii) test set with the rest. Estimate the ratings of the test set using the algorithms (same as in a) provided by the package on the training set. Your final rating should be weighted average of the ratings predicted by the algorithms. The weights should be learnt on the validation set. Performance should be measured in terms of RMSE.\n",
    "\n",
    "Hint: Use grid search/step-wise update like SGD for learning the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD\n",
    "from surprise.prediction_algorithms.matrix_factorization import NMF\n",
    "from surprise.prediction_algorithms.random_pred import NormalPredictor\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "from surprise.prediction_algorithms.baseline_only import BaselineOnly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9348  0.9424  0.9309  0.9374  0.9337  0.9359  0.0039  \n",
      "MAE (testset)     0.7363  0.7429  0.7339  0.7399  0.7374  0.7381  0.0031  \n",
      "Fit time          3.53    3.55    3.55    3.55    3.55    3.55    0.01    \n",
      "Test time         0.09    0.23    0.09    0.09    0.09    0.12    0.05    \n",
      "Evaluating RMSE, MAE of algorithm NMF on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9646  0.9610  0.9584  0.9631  0.9621  0.9618  0.0021  \n",
      "MAE (testset)     0.7602  0.7547  0.7522  0.7577  0.7560  0.7562  0.0027  \n",
      "Fit time          3.77    3.79    3.79    4.08    4.06    3.90    0.14    \n",
      "Test time         0.08    0.08    0.08    0.22    0.08    0.11    0.06    \n",
      "Evaluating RMSE, MAE of algorithm NormalPredictor on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.5250  1.5098  1.5069  1.5160  1.5314  1.5178  0.0092  \n",
      "MAE (testset)     1.2226  1.2129  1.2127  1.2180  1.2296  1.2191  0.0064  \n",
      "Fit time          0.08    0.09    0.10    0.09    0.10    0.09    0.01    \n",
      "Test time         0.11    0.09    0.09    0.08    0.09    0.09    0.01    \n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9884  0.9772  0.9758  0.9747  0.9828  0.9798  0.0051  \n",
      "MAE (testset)     0.7804  0.7719  0.7707  0.7701  0.7742  0.7734  0.0037  \n",
      "Fit time          0.24    0.24    0.24    0.25    0.23    0.24    0.00    \n",
      "Test time         2.29    2.14    2.14    2.15    2.30    2.21    0.07    \n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9535  0.9395  0.9428  0.9374  0.9457  0.9438  0.0056  \n",
      "MAE (testset)     0.7547  0.7434  0.7473  0.7447  0.7505  0.7481  0.0041  \n",
      "Fit time          0.15    0.18    0.19    0.16    0.16    0.17    0.02    \n",
      "Test time         0.08    0.08    0.24    0.07    0.07    0.11    0.07    \n"
     ]
    }
   ],
   "source": [
    "data = Dataset.load_builtin('ml-100k')\n",
    "algorithms = [SVD(),NMF(),NormalPredictor(),KNNBasic(),BaselineOnly()]\n",
    "for alg in algorithms:\n",
    "    cross_validate(alg, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,rest = train_test_split(data,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x150f63d908>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting rest to test and validate\n",
    "import random\n",
    "random.shuffle(rest)\n",
    "n = int(len(rest)/2)\n",
    "validate = rest[:n]\n",
    "test = rest[n:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "# training algorithms on the training set\n",
    "for alg in algorithms:\n",
    "    alg.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "W = [np.random.uniform(0.1) for i in range(len(algorithms))]\n",
    "for ins in validate:\n",
    "    out = [alg.test([ins])[0].est for alg in algorithms]\n",
    "    rating = ins[2]\n",
    "    pred_rating = np.dot(W,out)\n",
    "    error = rating - pred_rating\n",
    "    W = W + np.multiply(2*error*lr,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.03128100137997\n"
     ]
    }
   ],
   "source": [
    "RMSE = 0.0\n",
    "for ins in test:\n",
    "    out = [alg.test([ins])[0].est for alg in algorithms]\n",
    "    pred_rating = np.dot(W,out)\n",
    "    rating = ins[2]\n",
    "    #print ((pred_rating - rating)**2)\n",
    "    RMSE+= (rating - pred_rating)**2  \n",
    "RMSE = RMSE/len(test)\n",
    "print (np.sqrt(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Hidden Markov model\n",
    "Consider the HMM package https://hmmlearn.readthedocs.io/en/latest/\n",
    "\n",
    "a. Generate sequences with multinomial HMM (2 symbols and 4 hidden states) and given parameters. Start probability - {0.4,0.2,0.1,0.3}, Transition matrix - {{0.2,0.3,0.1,0.4},{0.3,0.3,0.2,0.2},{0.4,0.2,0.3,0.1},{0.2,0.3,0.1,0.4}}, Emission probability - {{0.2,0.8},{0.1,0.9},{0.5,0.5},{0.6,0.4}}.\n",
    "\n",
    "\n",
    "b. Consider a sequence - {1 0 0 0 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 1 0 1}. Fit a multinomial HMM considering 4 states and obtain hidden state w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn.hmm import MultinomialHMM\n",
    "model = MultinomialHMM(n_components=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.startprob_ = np.array([0.4, 0.2, 0.1,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.emissionprob_ = np.array([[0.2,0.8],[0.1,0.9],[0.5,0.5],[0.6,0.4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transmat_ = np.array([[0.2,0.3,0.1,0.4],[0.3,0.3,0.2,0.2],[0.4,0.2,0.3,0.1],[0.2,0.3,0.1,0.4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Z = model.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 0, 1, 2, 0, 1, 3, 3, 3, 1, 0, 1, 0, 0, 2, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1,0,0,0,1,1,1,1,0,1,0,1,0,1,0,1,1,1,0,0,0,1,1,0,1,0,0,1,1,0,1]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialHMM(algorithm='viterbi', init_params='ste', n_components=4,\n",
       "        n_iter=10, params='ste',\n",
       "        random_state=<mtrand.RandomState object at 0x10b4698b8>,\n",
       "        startprob_prior=1.0, tol=0.01, transmat_prior=1.0, verbose=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = MultinomialHMM(n_components=4)\n",
    "model2.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 1, 1, 2, 3, 0, 2, 3, 0, 1, 1, 1, 2, 3, 0, 1, 1, 2, 3])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-12.949709996850093,\n",
       " array([[3.10548214e-05, 2.86953190e-01, 7.13015755e-01, 1.71229469e-16],\n",
       "        [3.49782921e-01, 9.23456361e-02, 5.97809891e-02, 4.98090454e-01],\n",
       "        [1.88020845e-01, 4.13964540e-01, 3.90119840e-01, 7.89477545e-03],\n",
       "        [1.49952097e-01, 4.24396437e-01, 4.16710604e-01, 8.94086190e-03],\n",
       "        [1.01732519e-01, 3.95376788e-01, 4.92028558e-01, 1.08621356e-02],\n",
       "        [2.60476098e-01, 9.54190839e-02, 7.62377150e-02, 5.67867103e-01],\n",
       "        [4.58053362e-01, 1.02150744e-01, 6.22004563e-02, 3.77595437e-01],\n",
       "        [1.20561368e-01, 3.97179530e-01, 4.73751921e-01, 8.50718147e-03],\n",
       "        [2.61125441e-01, 9.70595058e-02, 7.77086419e-02, 5.64106411e-01],\n",
       "        [4.49075723e-01, 1.00599489e-01, 6.19533663e-02, 3.88371422e-01],\n",
       "        [1.75914395e-01, 4.18389541e-01, 3.98289942e-01, 7.40612222e-03],\n",
       "        [1.49217168e-01, 4.22164754e-01, 4.19228412e-01, 9.38966519e-03],\n",
       "        [1.51306768e-01, 4.23525491e-01, 4.15978843e-01, 9.18889737e-03],\n",
       "        [1.01753137e-01, 3.95422370e-01, 4.91975957e-01, 1.08485351e-02],\n",
       "        [2.59803461e-01, 9.57606484e-02, 7.66729921e-02, 5.67762898e-01],\n",
       "        [4.49443202e-01, 1.00464359e-01, 6.18482630e-02, 3.88244176e-01],\n",
       "        [1.75905466e-01, 4.18369678e-01, 3.98314595e-01, 7.41026094e-03],\n",
       "        [1.50140526e-01, 4.24014976e-01, 4.16804848e-01, 9.03965026e-03],\n",
       "        [1.05141254e-01, 3.95512424e-01, 4.88124598e-01, 1.12217246e-02],\n",
       "        [3.21597569e-01, 1.00246788e-01, 7.10175006e-02, 5.07138142e-01]]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.score_samples(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. PrefixSpan \n",
    "Implement the Prefix algorithm for Sequential Pattern Mining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
