{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# First home assignment Social Data Science"
      ],
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": [
        "Submit your solution by email to submission@cssh.rwth-aachen.de until 23.59pm on Wednesday, November 28th!\n",
        "Use \"[SDS] Submission Home Assignment 1\" as the email subject.\n",
        "\n",
        "You can (and should!) submit solutions in teams of up to three members.\n",
        "Please denote all members of the team with their student id and full name in the notebook as well as in the email body. Put all team members in email CC when submitting. Please submit only one email per team.\n",
        "\n",
        "Cite ALL your sources for coding this home assignment. In case of plagiarism (copying solutions from other teams or from the internet) ALL team members will be expelled from the course without warning.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement multiple linear regression by gradient descent\n",
        "Your implementation should be based on numpy arrays. Your implementation can use functions from the numpy library.\n",
        "\n",
        "Your function should have the signature\n",
        "linear_regression_gd (X,y,learning_rate) and should return a tuple (mean_squared_error_of_solution, [list_of_optimum_parameters])\n",
        "Here, X is a numpy array with the values of the explanatory variables, and y is an array with the dependent variable\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "#Display all content in dataframe\n",
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Formula:\n",
        "\n",
        "$\\beta^T = (b_0, b_1, ...b_j)$\n",
        "\n",
        "$C(\\beta) = \\frac{1}{2N}(Y-\\beta^T X)^2$\n",
        "\n$b_j = b_j - \\alpha \\frac{1}{N}\\sum_i^N(-Y_i + \\beta^TX_i)X_{ij}$"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Ref: https://towardsdatascience.com/gradient-descent-in-python-a0d07285742f\n",
        "\"\"\"\n",
        "    Gradient Descent\n",
        "    params: \n",
        "    -------------\n",
        "    X: explanatory varialbes\n",
        "    y: dependent variables\n",
        "    learning_rate: ratio to update parameter\n",
        "    max_iter: default 10000, maximum iterations of running updates\n",
        "    epsilon: default 0.001, threshold to break the loop\n",
        "    \n",
        "    returns:\n",
        "    ---------------\n",
        "    mse: mean squared error of the sulution\n",
        "    beta: list of optimum parameters\n",
        "\"\"\"\n",
        "def linear_regression_gd(X, y, learning_rate, max_iter=10000, epsilon=0.001):\n",
        "    N = len(y)\n",
        "    X = np.c_[np.ones(len(X)), X]  # add bias unit\n",
        "    features = X.shape[1]\n",
        "    beta = np.array(np.random.random(features)) # randonly choose initial parameters\n",
        "\n",
        "    for i in range(max_iter):\n",
        "        pred_y = np.dot(X, beta)\n",
        "        mse = np.sum(np.square(y - pred_y)) / (2 * N)\n",
        "        beta = beta - learning_rate * (np.dot(X.T, (pred_y - y))) / N\n",
        "        new_pred_y = np.dot(X, beta)\n",
        "        # if the update is so small, finish the gradient descent\n",
        "        if np.sum(np.square(new_pred_y, pred_y)) < epsilon:\n",
        "            break\n",
        "\n    return (mse, beta.tolist())"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extend your previous code to implement Stochastic Gradient Descent\n",
        "Your function should have the signature\n",
        "linear_regression_sgd (X,y,learning_rate, batch_size)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Stochastic Gradient Descent\n",
        "    params: \n",
        "    -------------\n",
        "    X: explanatory varialbes\n",
        "    y: dependent variables\n",
        "    learning_rate: ratio to update parameter\n",
        "    batch_size: number of samples used to train the model\n",
        "    max_iter: default 10000, maximum iterations of running updates\n",
        "    epsilon: default 0.001, threshold to break the loop\n",
        "    \n",
        "    returns:\n",
        "    ---------------\n",
        "    mse: mean squared error of the sulution\n",
        "    beta: list of optimum parameters\n",
        "    \n",
        "\"\"\"\n",
        "\n",
        "def linear_regression_sgd(X, y, learning_rate, batch_size=20, max_iter=10000, epsilon=0.001):\n",
        "    N = len(y)\n",
        "    features = X.shape[1] + 1 # one more feature for the bias unit\n",
        "    instances = X.shape[0]\n",
        "    beta = np.array(np.random.random(features))\n",
        "    for i in range(max_iter):\n",
        "        indices = np.random.choice(range(instances), batch_size)\n",
        "        X_batch = np.c_[np.ones(len(X[indices])), X[indices]] # add bias unit\n",
        "        y_batch = y[indices]\n",
        "        pred_y = np.dot(X_batch, beta)\n",
        "        mse = np.sum(np.square(y_batch - pred_y)) / (2 * N)\n",
        "        beta = beta - learning_rate * (np.dot(X_batch.T, (pred_y - y_batch))) / N\n",
        "        new_pred_y = np.dot(X_batch, beta)\n",
        "        if np.sum(np.square(new_pred_y, pred_y)) < epsilon:\n",
        "            break\n",
        "    return (mse, beta.tolist())"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the quality of Government Dataset \n",
        "from here: https://www.qogdata.pol.gu.se/data/qog_bas_cs_jan18.csv.\n",
        "The data is described here\n",
        "load it into a pandas dataframe and select the following columns:\n",
        "\"cname\",\"wdi_lifexp\",\"wdi_popden\",\"gle_cgdpc\",\"bti_acp\", \"bti_pdi\", \"fh_pair\", \"al_ethnic\",\"al_language\",\"al_religion\",\"bti_aar\",\"vdem_gender\",\"bti_ci\",\"bti_foe\",\"wdi_araland\", \"wdi_forest\"\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.qogdata.pol.gu.se/data/qog_bas_cs_jan18.csv'\n",
        "df = pd.read_csv(url)\n",
        "df = df[[\"cname\",\"wdi_lifexp\",\"wdi_popden\",\"gle_cgdpc\",\"bti_acp\", \n",
        "                              \"bti_pdi\", \"fh_pair\", \"al_ethnic\",\"al_language\",\"al_religion\",\n",
        "                              \"bti_aar\",\"vdem_gender\",\"bti_ci\",\"bti_foe\",\"wdi_araland\", \"wdi_forest\"]]\n",
        "df.drop(['cname'], axis=1, inplace=True)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wdi_lifexp</th>\n",
              "      <th>wdi_popden</th>\n",
              "      <th>gle_cgdpc</th>\n",
              "      <th>bti_acp</th>\n",
              "      <th>bti_pdi</th>\n",
              "      <th>fh_pair</th>\n",
              "      <th>al_ethnic</th>\n",
              "      <th>al_language</th>\n",
              "      <th>al_religion</th>\n",
              "      <th>bti_aar</th>\n",
              "      <th>vdem_gender</th>\n",
              "      <th>bti_ci</th>\n",
              "      <th>bti_foe</th>\n",
              "      <th>wdi_araland</th>\n",
              "      <th>wdi_forest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>62.902683</td>\n",
              "      <td>50.176178</td>\n",
              "      <td>1282.6400</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.769345</td>\n",
              "      <td>0.614146</td>\n",
              "      <td>0.271684</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.530792</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.903011</td>\n",
              "      <td>2.067825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>77.998390</td>\n",
              "      <td>105.441750</td>\n",
              "      <td>8516.7002</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9</td>\n",
              "      <td>0.220426</td>\n",
              "      <td>0.039925</td>\n",
              "      <td>0.471852</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.828077</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>22.467154</td>\n",
              "      <td>28.191971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>75.635025</td>\n",
              "      <td>16.422152</td>\n",
              "      <td>5402.1699</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7</td>\n",
              "      <td>0.339400</td>\n",
              "      <td>0.442662</td>\n",
              "      <td>0.009128</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.770516</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.136109</td>\n",
              "      <td>0.818057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>168.559570</td>\n",
              "      <td>32367.3300</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15</td>\n",
              "      <td>0.713946</td>\n",
              "      <td>0.684785</td>\n",
              "      <td>0.232569</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.957447</td>\n",
              "      <td>34.042553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60.806732</td>\n",
              "      <td>21.593380</td>\n",
              "      <td>3771.2000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.786720</td>\n",
              "      <td>0.787019</td>\n",
              "      <td>0.627644</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.680371</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.930376</td>\n",
              "      <td>46.507420</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   wdi_lifexp  wdi_popden   gle_cgdpc  bti_acp  bti_pdi  fh_pair  al_ethnic  \\\n",
              "0  62.902683   50.176178   1282.6400   3.0      3.0      2        0.769345    \n",
              "1  77.998390   105.441750  8516.7002   5.0      6.0      9        0.220426    \n",
              "2  75.635025   16.422152   5402.1699   5.0      3.0      7        0.339400    \n",
              "3 NaN          168.559570  32367.3300 NaN      NaN       15       0.713946    \n",
              "4  60.806732   21.593380   3771.2000   2.0      3.0      3        0.786720    \n",
              "\n",
              "   al_language  al_religion  bti_aar  vdem_gender  bti_ci  bti_foe  \\\n",
              "0  0.614146     0.271684     4.0      0.530792     9.0     4.0       \n",
              "1  0.039925     0.471852     8.0      0.828077     3.0     7.0       \n",
              "2  0.442662     0.009128     5.0      0.770516     7.0     6.0       \n",
              "3  0.684785     0.232569    NaN      NaN          NaN     NaN        \n",
              "4  0.787019     0.627644     3.0      0.680371     4.0     4.0       \n",
              "\n",
              "   wdi_araland  wdi_forest  \n",
              "0  11.903011    2.067825    \n",
              "1  22.467154    28.191971   \n",
              "2  3.136109     0.818057    \n",
              "3  5.957447     34.042553   \n",
              "4  3.930376     46.507420   "
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute the correlation of all other variables with the life expectancy (wdi_lifexp)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df_corr = df.dropna(axis=0) # drop na values for all rows\n",
        "\n",
        "df_all = df_corr.drop(['wdi_lifexp'], axis=1)\n",
        "variables = df_all.columns.tolist() # list of column names\n",
        "\n",
        "cov = [np.cov(df_corr['wdi_lifexp'], df_all[i])[1, 0] for i in variables]\n",
        "\n",
        "#calculate correlation coefficiant of wdi_lifexp with other features\n",
        "pearson_correlation = [np.corrcoef(df_corr['wdi_lifexp'], df_all[i])[1, 0] for i in variables]\n",
        "\n",
        "# pearson correlation and covariance table\n",
        "cov_table = pd.DataFrame(cov, columns=['Covariance'], index=variables)\n",
        "pearson_corr_table = pd.DataFrame(pearson_correlation, columns=['Pearson Correlation'], index=variables)\n",
        "pd.concat([pearson_corr_table, cov_table],axis=1,join='inner').sort_values('Pearson Correlation', ascending=False)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pearson Correlation</th>\n",
              "      <th>Covariance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>fh_pair</th>\n",
              "      <td>0.509754</td>\n",
              "      <td>13.432041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gle_cgdpc</th>\n",
              "      <td>0.497971</td>\n",
              "      <td>50262.103316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bti_acp</th>\n",
              "      <td>0.419631</td>\n",
              "      <td>6.291699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vdem_gender</th>\n",
              "      <td>0.200989</td>\n",
              "      <td>0.254124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bti_pdi</th>\n",
              "      <td>0.197603</td>\n",
              "      <td>4.047438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wdi_popden</th>\n",
              "      <td>0.190459</td>\n",
              "      <td>1062.117069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bti_foe</th>\n",
              "      <td>0.153353</td>\n",
              "      <td>2.728130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bti_aar</th>\n",
              "      <td>0.150202</td>\n",
              "      <td>3.071413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wdi_forest</th>\n",
              "      <td>0.087891</td>\n",
              "      <td>14.342895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wdi_araland</th>\n",
              "      <td>0.024516</td>\n",
              "      <td>2.659676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>al_religion</th>\n",
              "      <td>-0.314235</td>\n",
              "      <td>-0.563054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bti_ci</th>\n",
              "      <td>-0.423373</td>\n",
              "      <td>-6.886649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>al_ethnic</th>\n",
              "      <td>-0.601186</td>\n",
              "      <td>-1.095276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>al_language</th>\n",
              "      <td>-0.617282</td>\n",
              "      <td>-1.380360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Pearson Correlation    Covariance\n",
              "fh_pair      0.509754             13.432041   \n",
              "gle_cgdpc    0.497971             50262.103316\n",
              "bti_acp      0.419631             6.291699    \n",
              "vdem_gender  0.200989             0.254124    \n",
              "bti_pdi      0.197603             4.047438    \n",
              "wdi_popden   0.190459             1062.117069 \n",
              "bti_foe      0.153353             2.728130    \n",
              "bti_aar      0.150202             3.071413    \n",
              "wdi_forest   0.087891             14.342895   \n",
              "wdi_araland  0.024516             2.659676    \n",
              "al_religion -0.314235            -0.563054    \n",
              "bti_ci      -0.423373            -6.886649    \n",
              "al_ethnic   -0.601186            -1.095276    \n",
              "al_language -0.617282            -1.380360    "
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply your own implementations  (GD and SGD)\n",
        "To model the life expectancy from the population density and GDP per capita.\n",
        "Compare the results with what you get from scikit learn OR statsmodel libraries.\n",
        "\nFor this subtask, just remove all countries with missing values in any of these three variables."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df[['wdi_lifexp', 'wdi_popden', 'gle_cgdpc']].dropna(axis=0)\n",
        "X = df_test[['wdi_popden', 'gle_cgdpc']].values\n",
        "y = df_test['wdi_lifexp'].values\n",
        "# standarize the data\n",
        "X = preprocessing.scale(X)\n",
        "y = preprocessing.scale(y)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# use Gradient Decent\n",
        "\n",
        "params = linear_regression_gd(X, y, 0.01)\n",
        "my_gd_pred = [sum(r)+params[1][0] for r in np.array(params[1][1:])* X]\n",
        "\n",
        "print('model intercept: ', params[1][0])\n",
        "print('model parameters: ', params[1][1:])\n",
        "print('r2 score: ', r2_score(y, my_gd_pred))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model intercept:  2.8972823673845823e-16\n",
            "model parameters:  [0.03949066093307813, 0.6245564841445594]\n",
            "r2 score:  0.4020006760855134\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results of SGD models changes each time when you run it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# use Stochastic Gradient Descent\n",
        "\n",
        "params = linear_regression_sgd(X, y, 0.01)\n",
        "my_sgd_pred = [sum(r)+params[1][0] for r in np.array(params[1][1:])* X]\n",
        "\n",
        "print('model intercept: ', params[1][0])\n",
        "print('model parameters: ', params[1][1:])\n",
        "print('r2 score: ', r2_score(y, my_sgd_pred))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model intercept:  -0.00416427135790511\n",
            "model parameters:  [0.04797434957849235, 0.610497199183345]\n",
            "r2 score:  0.4017638490178921\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# # Stochastic Gradient Descent from sklearn library\n",
        "sk_SGD = SGDRegressor(max_iter=10000)\n",
        "sk_SGD.fit(X, y)\n",
        "pred_y = sk_SGD.predict(X)\n",
        "\n",
        "# ### Just compare the r2 score\n",
        "print('model intercept: ', sk_SGD.intercept_)\n",
        "print('model parameters: ', sk_SGD.coef_)\n",
        "print('r2 score: ', r2_score(y, pred_y))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model intercept:  [-7.74421318e-05]\n",
            "model parameters:  [0.03874848 0.62402598]\n",
            "r2 score:  0.4019996722677197\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build regression models to model the life expectancy (wdi_lifexp) in this dataset\n",
        "from all other mentioned variables.\n",
        "You can use scikit learn and/or statsmodels libraries for this task.\n",
        "Standardize variables and fill in missing values appropriately.\n",
        "Compare linear regression, Ridge regression and Lasso using k-fold-cross validation\n",
        "Test several parameters for the regularized regressions.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df_reg = df.copy()\n",
        "df_reg = df_reg.fillna(df_reg.mean())# fill na values with mean value\n",
        "\n",
        "y = df_reg['wdi_lifexp'].values\n",
        "X = df_reg.drop(['wdi_lifexp'], axis=1).values\n",
        "# standarize the data\n",
        "X = preprocessing.scale(X)\n",
        "y = preprocessing.scale(y)"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# linear regression\n",
        "fold = [5, 10, 20]\n",
        "scores = []\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X, y)\n",
        "for k in fold: \n",
        "    lin_val_score = cross_val_score(lin_reg, X, y, cv=k)\n",
        "    # calculate accuracy score = mean(validation_score) +/- std(validation_score)\n",
        "    accuracy = '{0:.3f}+/-{1:.3f}'.format(np.mean(lin_val_score), np.std(lin_val_score))\n",
        "    # calculate r2 score\n",
        "    r2_score = '{0:.3f} '.format(lin_reg.score(X, y))\n",
        "    score = [k, accuracy, r2_score]\n",
        "    scores.append(score)\n",
        "\npd.DataFrame(np.array(scores), columns=['fold', 'accuracy', 'r2 score'])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fold</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>r2 score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>0.660+/-0.105</td>\n",
              "      <td>0.699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>0.615+/-0.135</td>\n",
              "      <td>0.699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20</td>\n",
              "      <td>0.568+/-0.271</td>\n",
              "      <td>0.699</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  fold       accuracy r2 score\n",
              "0  5    0.660+/-0.105  0.699  \n",
              "1  10   0.615+/-0.135  0.699  \n",
              "2  20   0.568+/-0.271  0.699  "
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Regularization strength\n",
        "\"\"\"\n",
        "    Model validation to calcuate accuracy score and r2 score\n",
        "    params:\n",
        "    -------------\n",
        "    model: name for model, (Ridge, Lasso)\n",
        "    X: descriptive features\n",
        "    y: target features\n",
        "    fold: default 10, fold for cross validation\n",
        "    strength: default 0, strength for penalty\n",
        "    iter: default 1000, number of iterations\n",
        "    \n",
        "    returns: \n",
        "    --------------\n",
        "    accuracy: accuracy socre\n",
        "    model_r2_score: r2 score for the model\n",
        "\"\"\"\n",
        "def model_validation(model, X, y, fold=10, strength=0, iter=1000):\n",
        "    \n",
        "    model_reg = model(alpha=strength, max_iter=iter)\n",
        "    model_reg.fit(X, y)\n",
        "    \n",
        "    model_val_score = cross_val_score(model_reg, X, y, cv=fold)\n",
        "    model_r2_score = '{0:.3f} '.format(model_reg.score(X, y))\n",
        "    \n",
        "    # accuracy score = mean(validation_score) +/- std(validation_score)\n",
        "    accuracy = '{0:.3f}+/-{1:.3f}'.format(np.mean(model_val_score), np.std(model_val_score))\n",
        "    return accuracy, model_r2_score\n"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Evaluate the parameters\n",
        "    params:\n",
        "    -------------\n",
        "    model: name for model, (Ridge, Lasso)\n",
        "    X: descriptive features\n",
        "    y: target features\n",
        "    strength: default 0, strength for penalty\n",
        "    \n",
        "    returns: \n",
        "    --------------\n",
        "    dataframe to show table of results\n",
        "    \n",
        "\"\"\"\n",
        "\n",
        "def param_evaluation(model, X, y, strength):\n",
        "    scores = []\n",
        "    fold = [5, 10, 20]\n",
        "    for k in fold: \n",
        "        for alpha in strength:\n",
        "            accuracy, r2_score = model_validation(model, X, y, k, alpha)\n",
        "            score = [k, alpha, accuracy, r2_score]\n",
        "            scores.append(score)\n",
        "    return pd.DataFrame(np.array(scores), columns=['fold', 'Regularization strength', 'accuracy', 'r2 score'])"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine the results one dataframe to compare them."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "strength = [1, 50, 100, 150, 200]\n",
        "ridge_param = param_evaluation(Ridge, X, y, strength)\n",
        "\n",
        "strength = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "lasso_param = param_evaluation(Lasso, X, y, strength)"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "### Combine the results one dataframe\n",
        "pd.concat([ridge_param, lasso_param],keys=['Ridge','Lasso'],axis=1,join='inner')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"4\" halign=\"left\">Ridge</th>\n",
              "      <th colspan=\"4\" halign=\"left\">Lasso</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>fold</th>\n",
              "      <th>Regularization strength</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>r2 score</th>\n",
              "      <th>fold</th>\n",
              "      <th>Regularization strength</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>r2 score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.661+/-0.104</td>\n",
              "      <td>0.699</td>\n",
              "      <td>5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.599+/-0.080</td>\n",
              "      <td>0.620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "      <td>0.651+/-0.091</td>\n",
              "      <td>0.684</td>\n",
              "      <td>5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.538+/-0.057</td>\n",
              "      <td>0.555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>100</td>\n",
              "      <td>0.625+/-0.081</td>\n",
              "      <td>0.660</td>\n",
              "      <td>5</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.437+/-0.048</td>\n",
              "      <td>0.459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>150</td>\n",
              "      <td>0.596+/-0.074</td>\n",
              "      <td>0.635</td>\n",
              "      <td>5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.297+/-0.047</td>\n",
              "      <td>0.326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>200</td>\n",
              "      <td>0.567+/-0.069</td>\n",
              "      <td>0.610</td>\n",
              "      <td>5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.166+/-0.022</td>\n",
              "      <td>0.174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0.617+/-0.133</td>\n",
              "      <td>0.699</td>\n",
              "      <td>10</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.579+/-0.097</td>\n",
              "      <td>0.620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10</td>\n",
              "      <td>50</td>\n",
              "      <td>0.636+/-0.104</td>\n",
              "      <td>0.684</td>\n",
              "      <td>10</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.522+/-0.069</td>\n",
              "      <td>0.555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "      <td>0.621+/-0.095</td>\n",
              "      <td>0.660</td>\n",
              "      <td>10</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.422+/-0.061</td>\n",
              "      <td>0.459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10</td>\n",
              "      <td>150</td>\n",
              "      <td>0.598+/-0.090</td>\n",
              "      <td>0.635</td>\n",
              "      <td>10</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.278+/-0.056</td>\n",
              "      <td>0.326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>200</td>\n",
              "      <td>0.573+/-0.087</td>\n",
              "      <td>0.610</td>\n",
              "      <td>10</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.135+/-0.033</td>\n",
              "      <td>0.174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0.570+/-0.271</td>\n",
              "      <td>0.699</td>\n",
              "      <td>20</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.541+/-0.274</td>\n",
              "      <td>0.620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>20</td>\n",
              "      <td>50</td>\n",
              "      <td>0.591+/-0.250</td>\n",
              "      <td>0.684</td>\n",
              "      <td>20</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.486+/-0.224</td>\n",
              "      <td>0.555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>20</td>\n",
              "      <td>100</td>\n",
              "      <td>0.579+/-0.232</td>\n",
              "      <td>0.660</td>\n",
              "      <td>20</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.384+/-0.180</td>\n",
              "      <td>0.459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>20</td>\n",
              "      <td>150</td>\n",
              "      <td>0.559+/-0.219</td>\n",
              "      <td>0.635</td>\n",
              "      <td>20</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.238+/-0.142</td>\n",
              "      <td>0.326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>20</td>\n",
              "      <td>200</td>\n",
              "      <td>0.537+/-0.210</td>\n",
              "      <td>0.610</td>\n",
              "      <td>20</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.090+/-0.111</td>\n",
              "      <td>0.174</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Ridge                                                 Lasso  \\\n",
              "    fold Regularization strength       accuracy r2 score  fold   \n",
              "0   5     1                       0.661+/-0.104  0.699    5      \n",
              "1   5     50                      0.651+/-0.091  0.684    5      \n",
              "2   5     100                     0.625+/-0.081  0.660    5      \n",
              "3   5     150                     0.596+/-0.074  0.635    5      \n",
              "4   5     200                     0.567+/-0.069  0.610    5      \n",
              "5   10    1                       0.617+/-0.133  0.699    10     \n",
              "6   10    50                      0.636+/-0.104  0.684    10     \n",
              "7   10    100                     0.621+/-0.095  0.660    10     \n",
              "8   10    150                     0.598+/-0.090  0.635    10     \n",
              "9   10    200                     0.573+/-0.087  0.610    10     \n",
              "10  20    1                       0.570+/-0.271  0.699    20     \n",
              "11  20    50                      0.591+/-0.250  0.684    20     \n",
              "12  20    100                     0.579+/-0.232  0.660    20     \n",
              "13  20    150                     0.559+/-0.219  0.635    20     \n",
              "14  20    200                     0.537+/-0.210  0.610    20     \n",
              "\n",
              "                                                    \n",
              "   Regularization strength       accuracy r2 score  \n",
              "0   0.1                     0.599+/-0.080  0.620    \n",
              "1   0.2                     0.538+/-0.057  0.555    \n",
              "2   0.3                     0.437+/-0.048  0.459    \n",
              "3   0.4                     0.297+/-0.047  0.326    \n",
              "4   0.5                     0.166+/-0.022  0.174    \n",
              "5   0.1                     0.579+/-0.097  0.620    \n",
              "6   0.2                     0.522+/-0.069  0.555    \n",
              "7   0.3                     0.422+/-0.061  0.459    \n",
              "8   0.4                     0.278+/-0.056  0.326    \n",
              "9   0.5                     0.135+/-0.033  0.174    \n",
              "10  0.1                     0.541+/-0.274  0.620    \n",
              "11  0.2                     0.486+/-0.224  0.555    \n",
              "12  0.3                     0.384+/-0.180  0.459    \n",
              "13  0.4                     0.238+/-0.142  0.326    \n",
              "14  0.5                     0.090+/-0.111  0.174    "
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement Forward and Backward Selection algorithms\n",
        "And apply it to the (given subset of variables of the) Quality of Government dataset.\n",
        "Compare the results of Forward and Backward selection with each other.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Add one more predictor\n",
        "    params: \n",
        "    ------------\n",
        "    X: descriptive features\n",
        "    y: target features\n",
        "    old_predictors: already existing predictors\n",
        "    p: the chosen predictor to add\n",
        "    \n",
        "    returns: \n",
        "    -------------\n",
        "    dictionay of 'predictor', 'model' and 'sse'\n",
        "\"\"\"\n",
        "def add_predictor(X, y, old_predictors, p):\n",
        "    new_predictors = old_predictors + [p]\n",
        "    model = sm.OLS(y, X[new_predictors]) # linear regression to generate model\n",
        "    lin_reg = model.fit()\n",
        "    sse = np.sum((lin_reg.predict(X[new_predictors]) - y) ** 2)\n",
        "    return {'predictor':p, 'model':lin_reg, 'sse':sse}"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Forward algorithm to select best model\n",
        "    Ref: http://www.science.smith.edu/~jcrouser/SDS293/labs/2016/lab8/Lab%208%20-%20Subset%20Selection%20in%20Python.pdf\n",
        "    \n",
        "    params: \n",
        "    --------------\n",
        "    X: descriptive features\n",
        "    y: target features\n",
        "    old_predictors: already existing predictors\n",
        "    mse_full: mean square error while using all variables\n",
        "    \n",
        "    returns: \n",
        "    best_model: best model after applying the algorithm\n",
        "    mallow_cp: mallow cp value of the best model\n",
        "\"\"\"\n",
        "\n",
        "def forward(X, y, old_predictors, mse_full):\n",
        "    remain_predictors = [p for p in X.columns if p not in old_predictors]\n",
        "    results = []\n",
        "    for p in remain_predictors:\n",
        "        reg_model = add_predictor(X, y, old_predictors, p)\n",
        "        results.append(reg_model)\n",
        "    \n",
        "    models = pd.DataFrame(results)\n",
        "    best_model = models.loc[models['sse'].idxmin()] # get the best model (sse increast least)\n",
        "    best_predictor = best_model['predictor']\n",
        "    # mallow cp value for the best model\n",
        "    mallow_cp = best_model['sse'] / mse_full - X.shape[0] + 2 * (len(old_predictors)+1)\n",
        "    return best_model, mallow_cp"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Apply forward model selection\n",
        "    \n",
        "    params: \n",
        "    -------------\n",
        "    X: descriptive features\n",
        "    y: target features\n",
        "    \n",
        "    returns:\n",
        "    --------------\n",
        "    forward_model: a list of model choosen after adding predictors\n",
        "\"\"\"\n",
        "\n",
        "def forward_model_select(X, y):\n",
        "\n",
        "    model = sm.OLS(y, X)\n",
        "    lin_reg = model.fit()\n",
        "    pred_y = lin_reg.predict(X)\n",
        "    # mean squared error while using all variables\n",
        "    mse_full = np.mean(np.square(pred_y - y))\n",
        "\n",
        "    forward_model_table = {}\n",
        "    old_predictors = []\n",
        "    for index in range(X.shape[1]):\n",
        "        best_model, mallow_cp = forward(X, y, old_predictors, mse_full)\n",
        "        best_predictor = best_model['predictor']\n",
        "        old_predictors.append(best_predictor)\n",
        "        forward_model_table[index] = (mallow_cp, best_model['sse'], tuple(old_predictors))\n",
        "    \n",
        "    forward_model = pd.DataFrame(forward_model_table).transpose()\n",
        "    forward_model.columns = ['Mallow Cp', 'SSE', 'Predictors']\n",
        "    forward_model = forward_model.sort_values('Mallow Cp')\n",
        "    return forward_model # model 9 is the best"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df_selection = df.copy()\n",
        "df_selection = df_selection.fillna(df_selection.mean())# fill na values with mean value\n",
        "\n",
        "y = df_selection['wdi_lifexp'].values\n",
        "X = df_selection.drop(['wdi_lifexp'], axis=1)\n",
        "predictors = X.columns\n",
        "X = preprocessing.scale(X.values)\n",
        "y = preprocessing.scale(y)\n",
        "X = pd.DataFrame(X, columns=predictors)"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "forward_model_select(X, y) # model 9 is the best according to forward model selection"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mallow Cp</th>\n",
              "      <th>SSE</th>\n",
              "      <th>Predictors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>22.8765</td>\n",
              "      <td>59.1752</td>\n",
              "      <td>(fh_pair, al_language, gle_cgdpc, bti_aar, bti_ci, al_religion, wdi_popden, al_ethnic, vdem_gender, bti_acp)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>23.3403</td>\n",
              "      <td>58.7135</td>\n",
              "      <td>(fh_pair, al_language, gle_cgdpc, bti_aar, bti_ci, al_religion, wdi_popden, al_ethnic, vdem_gender, bti_acp, bti_pdi)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>24.0189</td>\n",
              "      <td>60.1197</td>\n",
              "      <td>(fh_pair, al_language, gle_cgdpc, bti_aar, bti_ci, al_religion, wdi_popden, al_ethnic, vdem_gender)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>24.3039</td>\n",
              "      <td>58.402</td>\n",
              "      <td>(fh_pair, al_language, gle_cgdpc, bti_aar, bti_ci, al_religion, wdi_popden, al_ethnic, vdem_gender, bti_acp, bti_pdi, wdi_forest)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>25.0354</td>\n",
              "      <td>61.0264</td>\n",
              "      <td>(fh_pair, al_language, gle_cgdpc, bti_aar, bti_ci, al_religion, wdi_popden, al_ethnic)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>26.0027</td>\n",
              "      <td>58.3114</td>\n",
              "      <td>(fh_pair, al_language, gle_cgdpc, bti_aar, bti_ci, al_religion, wdi_popden, al_ethnic, vdem_gender, bti_acp, bti_pdi, wdi_forest, bti_foe)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>26.3675</td>\n",
              "      <td>62.0279</td>\n",
              "      <td>(fh_pair, al_language, gle_cgdpc, bti_aar, bti_ci, al_religion, wdi_popden)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>28</td>\n",
              "      <td>58.3106</td>\n",
              "      <td>(fh_pair, al_language, gle_cgdpc, bti_aar, bti_ci, al_religion, wdi_popden, al_ethnic, vdem_gender, bti_acp, bti_pdi, wdi_forest, bti_foe, wdi_araland)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>30.3667</td>\n",
              "      <td>63.8311</td>\n",
              "      <td>(fh_pair, al_language, gle_cgdpc, bti_aar, bti_ci, al_religion)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35.8918</td>\n",
              "      <td>66.0929</td>\n",
              "      <td>(fh_pair, al_language, gle_cgdpc, bti_aar, bti_ci)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45.5769</td>\n",
              "      <td>69.6051</td>\n",
              "      <td>(fh_pair, al_language, gle_cgdpc, bti_aar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>55.7761</td>\n",
              "      <td>73.2719</td>\n",
              "      <td>(fh_pair, al_language, gle_cgdpc)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>110.247</td>\n",
              "      <td>90.2453</td>\n",
              "      <td>(fh_pair, al_language)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>181.534</td>\n",
              "      <td>112.273</td>\n",
              "      <td>(fh_pair,)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Mallow Cp      SSE  \\\n",
              "9   22.8765   59.1752   \n",
              "10  23.3403   58.7135   \n",
              "8   24.0189   60.1197   \n",
              "11  24.3039   58.402    \n",
              "7   25.0354   61.0264   \n",
              "12  26.0027   58.3114   \n",
              "6   26.3675   62.0279   \n",
              "13  28        58.3106   \n",
              "5   30.3667   63.8311   \n",
              "4   35.8918   66.0929   \n",
              "3   45.5769   69.6051   \n",
              "2   55.7761   73.2719   \n",
              "1   110.247   90.2453   \n",
              "0   181.534   112.273   \n",
              "\n",
              "                                                                                                                                                 Predictors  \n",
              "9   (fh_pair, al_language, gle_cgdpc, bti_aar, bti_ci, al_religion, wdi_popden, al_ethnic, vdem_gender, bti_acp)                                             \n",
              "10  (fh_pair, al_language, gle_cgdpc, bti_aar, bti_ci, al_religion, wdi_popden, al_ethnic, vdem_gender, bti_acp, bti_pdi)                                    \n",
              "8   (fh_pair, al_language, gle_cgdpc, bti_aar, bti_ci, al_religion, wdi_popden, al_ethnic, vdem_gender)                                                      \n",
              "11  (fh_pair, al_language, gle_cgdpc, bti_aar, bti_ci, al_religion, wdi_popden, al_ethnic, vdem_gender, bti_acp, bti_pdi, wdi_forest)                        \n",
              "7   (fh_pair, al_language, gle_cgdpc, bti_aar, bti_ci, al_religion, wdi_popden, al_ethnic)                                                                   \n",
              "12  (fh_pair, al_language, gle_cgdpc, bti_aar, bti_ci, al_religion, wdi_popden, al_ethnic, vdem_gender, bti_acp, bti_pdi, wdi_forest, bti_foe)               \n",
              "6   (fh_pair, al_language, gle_cgdpc, bti_aar, bti_ci, al_religion, wdi_popden)                                                                              \n",
              "13  (fh_pair, al_language, gle_cgdpc, bti_aar, bti_ci, al_religion, wdi_popden, al_ethnic, vdem_gender, bti_acp, bti_pdi, wdi_forest, bti_foe, wdi_araland)  \n",
              "5   (fh_pair, al_language, gle_cgdpc, bti_aar, bti_ci, al_religion)                                                                                          \n",
              "4   (fh_pair, al_language, gle_cgdpc, bti_aar, bti_ci)                                                                                                       \n",
              "3   (fh_pair, al_language, gle_cgdpc, bti_aar)                                                                                                               \n",
              "2   (fh_pair, al_language, gle_cgdpc)                                                                                                                        \n",
              "1   (fh_pair, al_language)                                                                                                                                   \n",
              "0   (fh_pair,)                                                                                                                                               "
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Remove one more predictor\n",
        "    params: \n",
        "    ------------\n",
        "    X: descriptive features\n",
        "    y: target features\n",
        "    old_predictors: already existing predictors\n",
        "    p: the chosen predictor to remove\n",
        "    \n",
        "    returns: \n",
        "    -------------\n",
        "    dictionay of 'predictor', 'model' and 'sse'\n",
        "\n",
        "\"\"\"\n",
        "def remove_predictor(X, y, old_predictors, p):\n",
        "    new_predictors = [s for s in old_predictors if s != p]\n",
        "    model = sm.OLS(y, X[new_predictors])\n",
        "    lin_reg = model.fit()\n",
        "    sse = np.sum((lin_reg.predict(X[new_predictors]) - y) ** 2)\n",
        "    return {'predictor':p, 'model':lin_reg, 'sse':sse}"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Backward algorithm to select best model\n",
        "    params: \n",
        "    --------------\n",
        "    X: descriptive features\n",
        "    y: target features\n",
        "    old_predictors: already existing predictors\n",
        "    mse_full: mean square error while using all variables\n",
        "    \n",
        "    returns: \n",
        "    best_model: best model after applying the algorithm\n",
        "    mallow_cp: mallow cp value of the best model\n",
        "\"\"\"\n",
        "\n",
        "def backward(X, y, old_predictors, mse_full):\n",
        "#     remain_predictors = old_predictors\n",
        "    results = []\n",
        "    for p in old_predictors:\n",
        "        reg_model = remove_predictor(X, y, old_predictors, p)\n",
        "        results.append(reg_model)\n",
        "    \n",
        "    models = pd.DataFrame(results)\n",
        "    best_model = models.loc[models['sse'].idxmin()]\n",
        "    best_predictor = best_model['predictor']\n",
        "    mallow_cp = best_model['sse'] / mse_full - X.shape[0] + 2 * (len(old_predictors)+1)\n",
        "    return best_model, mallow_cp"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Apply backward model selection\n",
        "    \n",
        "    params: \n",
        "    -------------\n",
        "    X: descriptive features\n",
        "    y: target features\n",
        "    \n",
        "    returns:\n",
        "    --------------\n",
        "    backward_model: a list of model choosen after removing predictors\n",
        "\"\"\"\n",
        "\n",
        "def backward_model_select(X, y):\n",
        "    backward_model_table = {}\n",
        "    old_predictors = X.columns\n",
        "    \n",
        "    model = sm.OLS(y, X)\n",
        "    lin_reg = model.fit()\n",
        "    pred_y = lin_reg.predict(X)\n",
        "    mse_full = np.mean(np.square(pred_y - y))\n",
        "\n",
        "    for index in range(X.shape[1]-1):\n",
        "        best_model, mallow_cp = backward(X, y, old_predictors, mse_full)\n",
        "        best_predictor = best_model['predictor']\n",
        "        \n",
        "        ### should remove p from old predictor first, then add it to the output table.\n",
        "        old_predictors = [p for p in old_predictors if p != best_predictor]\n",
        "        backward_model_table[index] = (mallow_cp, best_model['sse'], tuple(old_predictors))\n",
        "    \n",
        "    backward_model = pd.DataFrame(backward_model_table).transpose()\n",
        "    backward_model.columns = ['Mallow Cp', 'SSE', 'Predictors']\n",
        "    backward_model = backward_model.sort_values('Mallow Cp')\n",
        "    return backward_model # model 3 is the best"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "backward_model_select(X, y) # model 3 is the best according to forward model selection"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mallow Cp</th>\n",
              "      <th>SSE</th>\n",
              "      <th>Predictors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26.8765</td>\n",
              "      <td>59.1752</td>\n",
              "      <td>(wdi_popden, gle_cgdpc, bti_acp, fh_pair, al_ethnic, al_language, al_religion, bti_aar, vdem_gender, bti_ci)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27.3403</td>\n",
              "      <td>58.7135</td>\n",
              "      <td>(wdi_popden, gle_cgdpc, bti_acp, bti_pdi, fh_pair, al_ethnic, al_language, al_religion, bti_aar, vdem_gender, bti_ci)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27.8603</td>\n",
              "      <td>60.0721</td>\n",
              "      <td>(wdi_popden, gle_cgdpc, bti_acp, fh_pair, al_ethnic, al_language, al_religion, bti_aar, vdem_gender)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28.3039</td>\n",
              "      <td>58.402</td>\n",
              "      <td>(wdi_popden, gle_cgdpc, bti_acp, bti_pdi, fh_pair, al_ethnic, al_language, al_religion, bti_aar, vdem_gender, bti_ci, wdi_forest)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30.0027</td>\n",
              "      <td>58.3114</td>\n",
              "      <td>(wdi_popden, gle_cgdpc, bti_acp, bti_pdi, fh_pair, al_ethnic, al_language, al_religion, bti_aar, vdem_gender, bti_ci, bti_foe, wdi_forest)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>30.1679</td>\n",
              "      <td>61.3668</td>\n",
              "      <td>(wdi_popden, gle_cgdpc, bti_acp, fh_pair, al_ethnic, al_language, al_religion, bti_aar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>32.5081</td>\n",
              "      <td>62.6713</td>\n",
              "      <td>(wdi_popden, gle_cgdpc, bti_acp, fh_pair, al_language, al_religion, bti_aar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>37.6671</td>\n",
              "      <td>64.8231</td>\n",
              "      <td>(wdi_popden, gle_cgdpc, bti_acp, fh_pair, al_language, bti_aar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>42.887</td>\n",
              "      <td>66.9932</td>\n",
              "      <td>(gle_cgdpc, bti_acp, fh_pair, al_language, bti_aar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>49.5769</td>\n",
              "      <td>69.6051</td>\n",
              "      <td>(gle_cgdpc, fh_pair, al_language, bti_aar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>59.7761</td>\n",
              "      <td>73.2719</td>\n",
              "      <td>(gle_cgdpc, fh_pair, al_language)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>114.247</td>\n",
              "      <td>90.2453</td>\n",
              "      <td>(fh_pair, al_language)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>185.534</td>\n",
              "      <td>112.273</td>\n",
              "      <td>(fh_pair,)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Mallow Cp      SSE  \\\n",
              "3   26.8765   59.1752   \n",
              "2   27.3403   58.7135   \n",
              "4   27.8603   60.0721   \n",
              "1   28.3039   58.402    \n",
              "0   30.0027   58.3114   \n",
              "5   30.1679   61.3668   \n",
              "6   32.5081   62.6713   \n",
              "7   37.6671   64.8231   \n",
              "8   42.887    66.9932   \n",
              "9   49.5769   69.6051   \n",
              "10  59.7761   73.2719   \n",
              "11  114.247   90.2453   \n",
              "12  185.534   112.273   \n",
              "\n",
              "                                                                                                                                    Predictors  \n",
              "3   (wdi_popden, gle_cgdpc, bti_acp, fh_pair, al_ethnic, al_language, al_religion, bti_aar, vdem_gender, bti_ci)                                \n",
              "2   (wdi_popden, gle_cgdpc, bti_acp, bti_pdi, fh_pair, al_ethnic, al_language, al_religion, bti_aar, vdem_gender, bti_ci)                       \n",
              "4   (wdi_popden, gle_cgdpc, bti_acp, fh_pair, al_ethnic, al_language, al_religion, bti_aar, vdem_gender)                                        \n",
              "1   (wdi_popden, gle_cgdpc, bti_acp, bti_pdi, fh_pair, al_ethnic, al_language, al_religion, bti_aar, vdem_gender, bti_ci, wdi_forest)           \n",
              "0   (wdi_popden, gle_cgdpc, bti_acp, bti_pdi, fh_pair, al_ethnic, al_language, al_religion, bti_aar, vdem_gender, bti_ci, bti_foe, wdi_forest)  \n",
              "5   (wdi_popden, gle_cgdpc, bti_acp, fh_pair, al_ethnic, al_language, al_religion, bti_aar)                                                     \n",
              "6   (wdi_popden, gle_cgdpc, bti_acp, fh_pair, al_language, al_religion, bti_aar)                                                                \n",
              "7   (wdi_popden, gle_cgdpc, bti_acp, fh_pair, al_language, bti_aar)                                                                             \n",
              "8   (gle_cgdpc, bti_acp, fh_pair, al_language, bti_aar)                                                                                         \n",
              "9   (gle_cgdpc, fh_pair, al_language, bti_aar)                                                                                                  \n",
              "10  (gle_cgdpc, fh_pair, al_language)                                                                                                           \n",
              "11  (fh_pair, al_language)                                                                                                                      \n",
              "12  (fh_pair,)                                                                                                                                  "
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {
        "scrolled": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare the result\n",
        "|Selection method||||||||||||\n",
        "|------ | ------ | ------ |------ |------ |------ |------ |------ |------ |------ |------ |------ |\n",
        "| forward selection |al_language|al_religion|al_ethnic|bti_aar|bti_ci|bti_acp|fh_pair|gle_cgdpc|wdi_popden|vdem_gender|\n",
        "|backward selection|al_language|al_religion|al_ethnic|bti_aar|bti_ci|bti_acp|fh_pair|gle_cgdpc|wdi_popden|vdem_gender|\n",
        "\nSame result."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.7",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "toc": {
      "toc_position": {},
      "skip_h1_title": false,
      "number_sections": true,
      "title_cell": "Table of Contents",
      "toc_window_display": false,
      "base_numbering": 1,
      "toc_section_display": true,
      "title_sidebar": "Contents",
      "toc_cell": false,
      "nav_menu": {},
      "sideBar": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}