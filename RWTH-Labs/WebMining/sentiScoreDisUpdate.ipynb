{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get authors in 'The_Donald' and 'politics' subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time:  0.2668570000000001\n",
      "authors in The_Donald:  145776\n",
      "authors in politics:  251153\n",
      "authors in both The_Donald and politics:  48168\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "start_time = time.process_time()\n",
    "# Read author list from previously extracted author file\n",
    "don_author_list = []\n",
    "with open('./authorList/donList.txt') as file:\n",
    "    for author in file:\n",
    "        don_author_list.append(author.split('\\n')[0])\n",
    "pol_author_list = []\n",
    "with open('./authorList/polList.txt') as file:\n",
    "    for author in file:\n",
    "        pol_author_list.append(author.split('\\n')[0])\n",
    "# Read mutual author list from previously extracted author file\n",
    "mutual_author_list = []\n",
    "with open('./authorList/mutualAuthorList.txt') as file:\n",
    "    for author in file:\n",
    "        mutual_author_list.append(author.split('\\n')[0])\n",
    "\n",
    "end_time = time.process_time()\n",
    "print('running time: ', (end_time-start_time))\n",
    "print('authors in The_Donald: ', len(don_author_list))\n",
    "print('authors in politics: ', len(pol_author_list))\n",
    "print('authors in both The_Donald and politics: ', len(mutual_author_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentimental Score Distribution for each user in 'The_Donald' and 'politics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "def gextAuthorSentiscores(file_path, folder_path):\n",
    "    author_list = []\n",
    "    with open(file_path) as file:\n",
    "        for author in file:\n",
    "            author_list.append(author.split('\\n')[0])\n",
    "    # Initialize dict with value 0 and key are the authors\n",
    "    author_comm_count = {key: 0 for key in author_list}\n",
    "    author_scores = {key: 0 for key in author_list}\n",
    "\n",
    "#     folder_path = './The_Donald'\n",
    "    files = os.listdir(folder_path)\n",
    "    process = 0\n",
    "    file_num = len(files)\n",
    "    \n",
    "    for file in files:\n",
    "        process += 1\n",
    "        filename = '{0}/{1}'.format(folder_path, file)\n",
    "        try:\n",
    "            df = pd.read_csv(filename, sep='\\t')\n",
    "            authors = df['author']\n",
    "            for author in authors:\n",
    "                author_comm_count[author] += 1\n",
    "            for author in authors.unique(): # Get the sum of senti_score for each author\n",
    "                author_scores[author] += df.loc[df['author'] == author, ['senti_score']].sum()\n",
    "            print('Processing {0}/{1}'.format(process, file_num))\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        author_avgScore = {}\n",
    "        count_limit = 50 # Only concern those authors who post more than 50 comments\n",
    "        for author in author_comm_count.keys():\n",
    "            try:\n",
    "                if author_comm_count[author] > count_limit: # Calculate the average senti_score for each author\n",
    "                    author_avgScore[author] = author_scores[author] / author_comm_count[author]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # Convert average author senti_score dict to DataFrame, sort by senti_score\n",
    "    df_avgScore = pd.DataFrame(author_avgScore)\n",
    "    df_avgScore = df_avgScore.transpose().sort_values('senti_score', ascending=False)\n",
    "    return df_avgScore['senti_score'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average senti_score for each author in 'The_Donald' subreddit\n",
    "don_file_path = './donList.txt' # Path to the author list in 'The_Donald'\n",
    "don_folder_path = './The_Donald' # Previous extracted data folder\n",
    "don_authors_senti = getAuthorSentiscores(don_file_path, don_folder_path)\n",
    "# don_authors_senti.to_csv('./sentiscore_analysis/don_author.csv', sep='\\t')\n",
    "\n",
    "# Calculate average senti_score for each author in 'politics' subreddit\n",
    "pol_file_path = './polList.txt' # Path to the author list in 'politics'\n",
    "pol_folder_path = './politics'\n",
    "pol_authors_senti = getAuthorSentiscores(pol_file_path, pol_folder_path)\n",
    "# pol_authors_senti.to_csv('./sentiscore_analysis/pol_author.csv', sep='\\t')\n",
    "\n",
    "\n",
    "#Group data together\n",
    "hist_data = [don_authors_senti, pol_authors_senti]\n",
    "\n",
    "group_labels = ['don_senti_scores', 'pol_senti_scores']\n",
    "\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels, show_hist=False, bin_size=.2)\n",
    "\n",
    "# Plot\n",
    "py.iplot(fig, filename='Average Sentimental Score Distribution in two subreddits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual author behavior in  'The_Donald' and 'politics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from textblob import TextBlob\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "def muAuthSentiSubreddit(file_path, mu_auth_path, subreddit):\n",
    "    # Read the mutual author list\n",
    "    mutual_author_list = []\n",
    "    with open(mu_auth_path, 'r') as file:\n",
    "        for author in file:\n",
    "            mutual_author_list.append(author.split('\\n')[0])\n",
    "    \n",
    "    scores_list = []\n",
    "    with open(file_path, 'r+') as reddit_file:\n",
    "        for line in reddit_file:\n",
    "            if line:\n",
    "                try:\n",
    "                    jsn = json.loads(line)\n",
    "                    # Get the sentimental score where their mutual authors are also active in specific subreddit\n",
    "                    if jsn['subreddit'] == subreddit and jsn['author'] in mutual_author_list:\n",
    "                        statement = jsn['body']\n",
    "                        sentiment = TextBlob(statement)\n",
    "                        score = sentiment.sentiment.polarity # Calculate polarity score\n",
    "                        subjectivity = sentiment.sentiment.subjectivity # # Calculate subjectivity score\n",
    "                        if subjectivity > 0.3:\n",
    "                            scores_list.append(score)\n",
    "                except:\n",
    "                    pass\n",
    "    return scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './cleands2' # path to the dataset\n",
    "mu_auth_path = './authorList/mutualAuthorList.txt' # path to the mutual author list\n",
    "don_score_list = muAuthSentiSubreddit(file_path, mu_auth_path, 'The_Donald') \n",
    "pol_score_list = muAuthSentiSubreddit(file_path, mu_auth_path, 'politics') \n",
    "\n",
    "#Group data together\n",
    "hist_data = [don_score_list, pol_score_list]\n",
    "\n",
    "group_labels = ['senti_score in \"The_Donald\"', 'senti_score in \"politics\"']\n",
    "\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels,show_hist=False, bin_size=.2)\n",
    "\n",
    "# Plot!\n",
    "py.iplot(fig, filename='Mutual_Author_Sentimental_Score_Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual author behavior comparison with other subreddits, like 'AskReddit', 'news'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiScoreComparison(score_list, don_score_list, pol_score_list):\n",
    "   \n",
    "    #Group data together\n",
    "\n",
    "    hist_data = [don_score_list, pol_score_list, score_list]\n",
    "\n",
    "    group_labels = ['senti_score in \"The_Donald\"', 'senti_score in \"politics\"', 'senti_score in \"news\"']\n",
    "\n",
    "    # Create distplot with custom bin_size\n",
    "    fig = ff.create_distplot(hist_data, group_labels,show_hist=False, bin_size=.2)\n",
    "\n",
    "#     Plot!\n",
    "    return py.iplot(fig, filename='Mutual_Author_Sentimental_Score_Distribution Comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sentimental score for mutual author in 'news' subreddit\n",
    "news_score_list = muAuthSentiSubreddit(file_path, mu_auth_path, 'news') \n",
    "# Plot comparison figure\n",
    "sentiScoreComparison(news_score_list, don_score_list, pol_score_list)\n",
    "\n",
    "# Get sentimental score for mutual author in 'AskReddit' subreddit\n",
    "askreddit_score_list = muAuthSentiSubreddit(file_path, mu_auth_path, 'AskReddit')\n",
    "# Plot comparison figure\n",
    "sentiScoreComparison(askreddit_score_list, don_score_list, pol_score_list)\n",
    "\n",
    "# Get sentimental score for mutual author in 'world_news subreddit\n",
    "worldnews_score_list = muAuthSentiSubreddit(file_path, mu_auth_path, 'world_news')\n",
    "# Plot comparison figure\n",
    "sentiScoreComparison(worldnews_score_list, don_score_list, pol_score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentimental Score Distribution per post in 'The_Donald' and 'politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def getSentiScore(file_path):\n",
    "    high_comm_files = os.listdir(file_path)\n",
    "    \n",
    "    senti_scores = []\n",
    "    \n",
    "    for file in high_comm_files:\n",
    "        filename = file_path + file\n",
    "        try:\n",
    "            df_high_comm = pd.read_csv(filename, sep='\\t')\n",
    "            senti_scores += df_high_comm['senti_score'].tolist() # Obtain senti_score to score list\n",
    "        except:\n",
    "            pass\n",
    "    return senti_scores\n",
    "\n",
    "don_file_path = './The_Donald/'\n",
    "don_senti_score = getSentiScore(don_file_path)\n",
    "pol_file_path = './politics/'\n",
    "pol_senti_score = getSentiScore(pol_file_path)\n",
    "\n",
    "\n",
    "#Group data together\n",
    "# Use sample data, take 10K data to plot histgram\n",
    "hist_data = [don_senti_score[:10000], pol_senti_score[:10000]]\n",
    "\n",
    "group_labels = ['don_senti_score', 'pol_senti_score']\n",
    "\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels,show_hist=False, bin_size=.2)\n",
    "\n",
    "# Plot!\n",
    "py.iplot(fig, filename='Sentimental Score Distribution in two subreddits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentimental Score Distribution according to some key words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def keyWordsSentiDistribution(file_path, subreddit, keywords):\n",
    "    scores_list = []\n",
    "    with open(file_path, 'r+') as reddit_file:\n",
    "        for line in reddit_file:\n",
    "            if line:\n",
    "                try:\n",
    "                    jsn = json.loads(line)\n",
    "                    # Get the sentimental score where keywords appear in the comment body\n",
    "                    if jsn['subreddit'] == subreddit and keywords.lower() in jsn['body'].lower():\n",
    "                        statement = jsn['body']\n",
    "                        sentiment = TextBlob(statement)\n",
    "                        score = sentiment.sentiment.polarity # Calculate polarity score\n",
    "                        score = round(float(score), 4)\n",
    "                        scores_list.append(score)\n",
    "                except:\n",
    "                    pass\n",
    "    return scores_list\n",
    "\n",
    "def KeyWordsComparison(subreddit, keywords):\n",
    "    file_path = './cleands2' # path to the dataset\n",
    "    keywords_score_list = {}\n",
    "    for i in range(len(subreddit)):\n",
    "        keywords_score_list[i] = keyWordsSentiDistribution(file_path, subreddit[i], keywords)\n",
    "    \n",
    "    #Group data together\n",
    "\n",
    "    hist_data = [keywords_score_list[0], keywords_score_list[1], keywords_score_list[2]]\n",
    "\n",
    "    group_labels = ['senti_score in \"The_Donald\"', 'senti_score in \"politics\"', 'senti_score in \"news\"']\n",
    "\n",
    "    # Create distplot with custom bin_size\n",
    "    fig = ff.create_distplot(hist_data, group_labels,show_hist=False, bin_size=.2)\n",
    "\n",
    "    # Plot!\n",
    "    return py.iplot(fig, filename='Sentimental Score Distribution about certian keywords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords like 'Trump', 'Hillary' might be interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentimental score distribution about 'trump'\n",
    "KeyWordsComparison(['The_Donald', 'politics', 'news'], 'trump')\n",
    "\n",
    "# Sentimental score distribution about 'trump'\n",
    "KeyWordsComparison(['The_Donald', 'politics', 'news'], 'hillary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
