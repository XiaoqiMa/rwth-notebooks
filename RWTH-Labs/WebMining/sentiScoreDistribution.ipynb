{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get authors in 'The_Donald' and 'politics' subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time:  0.26112500000000005\n",
      "authors in The_Donald:  145776\n",
      "authors in politics:  251153\n",
      "authors in both The_Donald and politics:  48168\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "start_time = time.process_time()\n",
    "# Read author list from previously extracted author file\n",
    "don_author_list = []\n",
    "with open('./authorList/donList.txt') as file:\n",
    "    for author in file:\n",
    "        don_author_list.append(author.split('\\n')[0])\n",
    "pol_author_list = []\n",
    "with open('./authorList/polList.txt') as file:\n",
    "    for author in file:\n",
    "        pol_author_list.append(author.split('\\n')[0])\n",
    "# Read mutual author list from previously extracted author file\n",
    "mutual_author_list = []\n",
    "with open('./authorList/mutualAuthorList.txt') as file:\n",
    "    for author in file:\n",
    "        mutual_author_list.append(author.split('\\n')[0])\n",
    "\n",
    "end_time = time.process_time()\n",
    "print('running time: ', (end_time-start_time))\n",
    "print('authors in The_Donald: ', len(don_author_list))\n",
    "print('authors in politics: ', len(pol_author_list))\n",
    "print('authors in both The_Donald and politics: ', len(mutual_author_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentimental Score Distribution for users in subreddits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def getAuthorSentiscores(file_path, folder_path):\n",
    "    author_list = []\n",
    "    with open(file_path) as file:\n",
    "        for author in file:\n",
    "            author_list.append(author.split('\\n')[0])\n",
    "    # Initialize dict with value 0 and key are the authors\n",
    "    author_comm_count = {key: 0 for key in author_list}\n",
    "    author_scores = {key: 0 for key in author_list}\n",
    "\n",
    "#     folder_path = './The_Donald'\n",
    "    files = os.listdir(folder_path)\n",
    "    process = 0\n",
    "    file_num = len(files)\n",
    "    \n",
    "    for file in files:\n",
    "        process += 1\n",
    "        filename = '{0}/{1}'.format(folder_path, file)\n",
    "        try:\n",
    "            df = pd.read_csv(filename, sep='\\t')\n",
    "            authors = df['author']\n",
    "            for author in authors:\n",
    "                author_comm_count[author] += 1\n",
    "            for author in authors.unique(): # Get the sum of senti_score for each author\n",
    "                author_scores[author] += df.loc[df['author'] == author, ['senti_score']].sum()\n",
    "            print('Processing {0}/{1}'.format(process, file_num))\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        author_avgScore = {}\n",
    "        count_limit = 50 # Only concern those authors who post more than 50 comments\n",
    "        for author in author_comm_count.keys():\n",
    "            try:\n",
    "                if author_comm_count[author] > count_limit: # Calculate the average senti_score for each author\n",
    "                    author_avgScore[author] = author_scores[author] / author_comm_count[author]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # Convert average author senti_score dict to DataFrame, sort by senti_score\n",
    "    df_avgScore = pd.DataFrame(author_avgScore)\n",
    "    df_avgScore = df_avgScore.transpose().sort_values('senti_score', ascending=False)\n",
    "    return df_avgScore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average senti_score for each author in 'The_Donald' subreddit\n",
    "don_file_path = './donList.txt'\n",
    "don_folder_path = './The_Donald'\n",
    "don_authors_senti = getAuthorSentiscores(don_file_path, don_folder_path)\n",
    "don_authors_senti.to_csv('./sentiscore_analysis/don_author.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average senti_score for each author in 'politics' subreddit\n",
    "pol_file_path = './polList.txt'\n",
    "pol_folder_path = './politics'\n",
    "pol_authors_senti = getAuthorSentiscores(pol_file_path, pol_folder_path)\n",
    "pol_authors_senti.to_csv('./sentiscore_analysis/pol_author.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# Read file from previously extracted\n",
    "don_file_path = './sentiscore_analysis/don_author.csv'\n",
    "don_senti_score = pd.read_csv(don_file_path, sep='\\t')\n",
    "don_senti_scores = don_senti_score['senti_score'].values\n",
    "\n",
    "pol_file_path = './sentiscore_analysis/pol_author.csv'\n",
    "pol_senti_score = pd.read_csv(pol_file_path, sep='\\t')\n",
    "pol_senti_scores = pol_senti_score['senti_score'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of don senti scores 10107\n",
      "length of pol senti scores 15655\n"
     ]
    }
   ],
   "source": [
    "print('length of don senti scores', len(don_senti_scores))\n",
    "print('length of pol senti scores', len(pol_senti_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group data together\n",
    "hist_data = [don_senti_scores, pol_senti_scores]\n",
    "\n",
    "group_labels = ['don_senti_scores', 'pol_senti_scores']\n",
    "\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels, show_hist=False, bin_size=.2)\n",
    "\n",
    "# Plot\n",
    "py.iplot(fig, filename='Average Sentimental Score Distribution in two subreddits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual author behavior in  'The_Donald' and 'politics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMuAuthSentiScore(mu_auth_path, file_path):\n",
    "    # Extract the mutual author lists\n",
    "    mutual_author_list = []\n",
    "    with open(mu_auth_path) as file:\n",
    "        for author in file:\n",
    "            mutual_author_list.append(author.split('\\n')[0])\n",
    "    \n",
    "    # Initialize the defalut dict to store the senti socres\n",
    "    mu_author_dict = {key:1 for key in mutual_author_list}\n",
    "    \n",
    "    author_score = pd.read_csv(file_path, sep='\\t', names=['author', 'senti_score'])\n",
    "    # For each author, obtain the senti_score and save\n",
    "    for author in mu_author_dict.keys():\n",
    "        score = author_score.loc[author_score['author'] == author, ['senti_score']].values\n",
    "        if len(score) > 0:\n",
    "            mu_author_dict[author] = score[0][0]\n",
    "    # Filter out those senti_score=1, which means no comment occurence for this author\n",
    "    mu_author_score = {}\n",
    "    for key, value in mu_author_dict.items():\n",
    "        if value != 1:\n",
    "            mu_author_score[key] = value\n",
    "    mu_author_score = [round(float(x),4) for x in mu_author_score.values()]\n",
    "    return mu_author_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_auth_path = './authorList/mutualAuthorList.txt'\n",
    "don_file_path = './sentiscore_analysis/don_author.csv'\n",
    "pol_file_path = './sentiscore_analysis/pol_author.csv'\n",
    "mu_author_don = getMuAuthSentiScore(mu_auth_path, don_file_path)\n",
    "mu_author_pol = getMuAuthSentiScore(mu_auth_path, pol_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "\n",
    "#Group data together\n",
    "hist_data = [mu_author_don, mu_author_pol]\n",
    "\n",
    "group_labels = ['don_senti_score', 'pol_senti_score']\n",
    "\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels,show_hist=False, bin_size=.2)\n",
    "\n",
    "# Plot!\n",
    "# py.iplot(fig, filename='Mutual_Author_Sentimental_Score_Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual author behavior comparison with other subreddits, like 'AskReddit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from textblob import TextBlob\n",
    "\n",
    "def muAuthSentiSubreddit(file_path, mu_auth_path, subreddit):\n",
    "    # Read the mutual author list\n",
    "    mutual_author_list = []\n",
    "    with open(mu_auth_path, 'r') as file:\n",
    "        for author in file:\n",
    "            mutual_author_list.append(author.split('\\n')[0])\n",
    "    \n",
    "    scores_list = []\n",
    "    with open(file_path, 'r+') as reddit_file:\n",
    "        for line in reddit_file:\n",
    "            if line:\n",
    "                try:\n",
    "                    jsn = json.loads(line)\n",
    "                    # Get the sentimental score where their mutual authors are also active in specific subreddit\n",
    "                    if jsn['subreddit'] == subreddit and jsn['author'] in mutual_author_list:\n",
    "                        statement = jsn['body']\n",
    "                        sentiment = TextBlob(statement)\n",
    "                        score = sentiment.sentiment.polarity # Calculate polarity score\n",
    "                        subjectivity = sentiment.sentiment.subjectivity # # Calculate subjectivity score\n",
    "                        if subjectivity > 0.3:\n",
    "                            scores_list.append(score)\n",
    "                except:\n",
    "                    pass\n",
    "    return scores_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sentiScoreComparison(score_path, don_score_list, pol_score_list):\n",
    "def sentiScoreComparison(score_path):\n",
    "    score_list = []\n",
    "    with open(score_path, 'r') as file:\n",
    "        for score in file:\n",
    "            score = round(float(score.split('\\n')[0]), 4)\n",
    "            score_list.append(score)\n",
    "    return score_list\n",
    "    #Group data together\n",
    "\n",
    "#     hist_data = [don_score_list, pol_score_list, score_list[:8000]]\n",
    "\n",
    "#     group_labels = ['senti_score in \"The_Donald\"', 'senti_score in \"politics\"', 'senti_score in \"news\"']\n",
    "\n",
    "#     # Create distplot with custom bin_size\n",
    "#     fig = ff.create_distplot(hist_data, group_labels,show_hist=False, bin_size=.2)\n",
    "\n",
    "    # Plot!\n",
    "#     return py.iplot(fig, filename='Mutual_Author_Sentimental_Score_Distribution Comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "don_path = './sentiscore_analysis/the_donald_score_list.csv'\n",
    "don_list = sentiScoreComparison(don_path)[:6000]\n",
    "pol_path = './sentiscore_analysis/politics_score_list.csv'\n",
    "pol_list = sentiScoreComparison(pol_path)[:6000]\n",
    "news_path = './sentiscore_analysis/news_score_list.csv'\n",
    "news_list = sentiScoreComparison(news_path)[:6000]\n",
    "world_news_path = './sentiscore_analysis/news_score_list.csv'\n",
    "world_news_list = sentiScoreComparison(world_news_path)[:6000]\n",
    "ask_reddit_path = './sentiscore_analysis/askreddit_score_list.csv'\n",
    "askreddit_list = sentiScoreComparison(ask_reddit_path)[:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data = [don_list, pol_list, askreddit_list, news_list, world_news_list]\n",
    "\n",
    "group_labels = ['senti_score in \"The_Donald\"', 'senti_score in \"politics\"', 'senti_score in \"AskReddit\"', 'senti_score in \"news\"', 'senti_score in \"world_news\"']\n",
    "\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels,show_hist=False, bin_size=.2)\n",
    "\n",
    "    # Plot!\n",
    "# py.iplot(fig, filename='Mutual_Author_Sentimental_Score_Distribution_Comparison')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Sentimental Score Distribution in 'The_Donald' and 'politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def getSentiScore(file_path):\n",
    "    high_comm_files = os.listdir(file_path)\n",
    "    \n",
    "    senti_scores = []\n",
    "    \n",
    "    for file in high_comm_files:\n",
    "        filename = file_path + file\n",
    "        try:\n",
    "            df_high_comm = pd.read_csv(filename, sep='\\t')\n",
    "            senti_scores += df_high_comm['senti_score'].tolist() # Obtain senti_score to score list\n",
    "        except:\n",
    "            pass\n",
    "    return senti_scores\n",
    "\n",
    "don_file_path = './The_Donald/'\n",
    "don_senti_score = getSentiScore(don_file_path)\n",
    "pol_file_path = './politics/'\n",
    "pol_senti_score = getSentiScore(pol_file_path)\n",
    "\n",
    "\n",
    "#Group data together\n",
    "# Use sample data, take 10K data to plot histgram\n",
    "hist_data = [don_senti_score[:10000], pol_senti_score[:10000]]\n",
    "\n",
    "group_labels = ['don_senti_score', 'pol_senti_score']\n",
    "\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels,show_hist=False, bin_size=.2)\n",
    "\n",
    "# Plot!\n",
    "py.iplot(fig, filename='Sentimental Score Distribution in two subreddits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentimental Score Distribution according to some key words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def getSentiScore(file_path, keywords):\n",
    "    \n",
    "    high_comm_files = os.listdir(file_path)\n",
    "    \n",
    "    senti_scores = []\n",
    "    comments = []\n",
    "    \n",
    "    for file in high_comm_files:\n",
    "        filename = file_path + file\n",
    "        try:\n",
    "            df_high_comm = pd.read_csv(filename, sep='\\t')\n",
    "            for i in range(len(df_high_comm)):\n",
    "                # To check whether the comment body contains the keyword\n",
    "                if keywords.lower() in df_high_comm['body'][i].lower():\n",
    "#                     comments.append(df_high_comm['body'][i])\n",
    "                    senti_scores.append(df_high_comm['senti_score'][i])\n",
    "        except:\n",
    "            pass\n",
    "    return senti_scores         \n",
    "\n",
    "\n",
    "\n",
    "def keyWordsSentiDistribution(keywords):\n",
    "    don_file_path = './The_Donald/'\n",
    "    pol_file_path = './politics/'\n",
    "    don_senti_score = getSentiScore(don_file_path, keywords)\n",
    "    pol_senti_score = getSentiScore(pol_file_path, keywords)\n",
    "    \n",
    "#     return don_senti_score[:10000], pol_senti_score[:10000]\n",
    "    #Group data together\n",
    "    hist_data = [don_senti_score[:10000], pol_senti_score[:10000]]\n",
    "\n",
    "    group_labels = ['don_senti_score', 'pol_senti_score']\n",
    "\n",
    "    # Create distplot with custom bin_size\n",
    "    fig = ff.create_distplot(hist_data, group_labels, bin_size=.2)\n",
    "\n",
    "    # Plot!\n",
    "    return py.iplot(fig, filename='Sentimental Score Distribution')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyWordsSentiDistribution(file_path, subreddit, keywords):\n",
    "    scores_list = []\n",
    "    with open(file_path, 'r+') as reddit_file:\n",
    "        for line in reddit_file:\n",
    "            if line:\n",
    "                try:\n",
    "                    jsn = json.loads(line)\n",
    "                    # Get the sentimental score where keywords appear in the comment body\n",
    "                    if jsn['subreddit'] == subreddit and keywords in jsn['body']:\n",
    "                        statement = jsn['body']\n",
    "                        sentiment = TextBlob(statement)\n",
    "                        score = sentiment.sentiment.polarity # Calculate polarity score\n",
    "                        score = round(float(score), 4)\n",
    "                        scores_list.append(score)\n",
    "                except:\n",
    "                    pass\n",
    "    return scores_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords like 'Trump', 'Hillary', 'Election' might be interesting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyWordsSentiDistribution('trump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyWordsSentiDistribution('Hillary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyWordsSentiDistribution('election')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
