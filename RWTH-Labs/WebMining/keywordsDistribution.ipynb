{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from textblob import TextBlob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyWordsSentiDistribution(file_path, subreddit, keywords):\n",
    "    scores_list = []\n",
    "    with open(file_path, 'r+') as reddit_file:\n",
    "        for line in reddit_file:\n",
    "            if line:\n",
    "                try:\n",
    "                    jsn = json.loads(line)\n",
    "                    # Get the sentimental score where keywords appear in the comment body\n",
    "                    if jsn['subreddit'] == subreddit and keywords.lower() in jsn['body'].lower():\n",
    "                        statement = jsn['body']\n",
    "                        sentiment = TextBlob(statement)\n",
    "                        score = sentiment.sentiment.polarity # Calculate polarity score\n",
    "                        score = round(float(score), 4)\n",
    "                        scores_list.append(score)\n",
    "                except:\n",
    "                    pass\n",
    "    return scores_list[:8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KeyWordsComparison(subreddit, keywords):\n",
    "    file_path = '/Users/xiaoqi/reddit-datasets/cleands2'\n",
    "    scores_dict = {}\n",
    "    for i in range(len(subreddit)):\n",
    "        scores_dict[i] = keyWordsSentiDistribution(file_path, subreddit[i], keywords)\n",
    "    \n",
    "    return scores_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with time:  3089.234782\n"
     ]
    }
   ],
   "source": [
    "start_time = time.process_time()\n",
    "file_path = '/Users/xiaoqi/reddit-datasets/cleands2'\n",
    "\n",
    "don = KeyWordsComparison(['The_Donald', 'politics', 'news'], 'trump')\n",
    "\n",
    "end_time = time.process_time()\n",
    "print('done with time: ', end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#Group data together\n",
    "# Use sample data, take 10K data to plot histgram\n",
    "\n",
    "hist_data = [don[0], don[1], don[2]]\n",
    "\n",
    "group_labels = ['senti_score in \"The_Donald\"', 'senti_score in \"politics\"', 'senti_score in \"news\"']\n",
    "\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels,show_hist=False, bin_size=.2)\n",
    "\n",
    "# Plot!\n",
    "# py.iplot(fig, filename='Sentimental Score Distribution in two subreddits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with time:  2614.5600270000004\n"
     ]
    }
   ],
   "source": [
    "start_time = time.process_time()\n",
    "file_path = '/Users/xiaoqi/reddit-datasets/cleands2'\n",
    "\n",
    "hillary = KeyWordsComparison(['The_Donald', 'politics', 'news'], 'hillary')\n",
    "\n",
    "end_time = time.process_time()\n",
    "print('done with time: ', end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.process_time()\n",
    "file_path = '/Users/xiaoqi/reddit-datasets/cleands2'\n",
    "\n",
    "don = KeyWordsComparison(['The_Donald', 'politics', 'news'], 'election')\n",
    "\n",
    "end_time = time.process_time()\n",
    "print('done with time: ', end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~xiaoqima/12.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_data = [hillary[0], hillary[1], hillary[2]]\n",
    "\n",
    "group_labels = ['senti_score in \"The_Donald\"', 'senti_score in \"politics\"', 'senti_score in \"news\"']\n",
    "\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels,show_hist=False, bin_size=.2)\n",
    "\n",
    "# Plot!\n",
    "py.iplot(fig, filename='Sentimental Score Distribution in two subreddits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
